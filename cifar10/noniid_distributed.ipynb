{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ea70b5-8573-4295-8c73-bee181d96e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d9ba4a-4dcc-4024-829a-d17454cdb6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"./saved_models/noniid/run3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8467a8be-c495-478e-b827-3e26a32272f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0993d1f-43dd-499e-91f9-d7d8522d6336",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5097bcab-4299-4946-b4b5-aed6ff7d6ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd71d799-bf6b-4bd1-8b17-6c2904da8ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch%10==0:\n",
    "        print('Epoch%d, Loss: %.3f' % (epoch, train_loss/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7607a6b-e71e-4f1c-a4b4-9b8b5175e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    return 1.0*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3baf90dd-2f6e-4dc9-83c2-88c4dc676642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learner(dataset, epochs, net=None):\n",
    "    if net is None:\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    for epoch in range(epochs):\n",
    "        train(net, trainloader, optimizer, epoch)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71e9373-6455-44a3-a7f5-fbb443f13f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(learners, local_sets, theta, epochs):\n",
    "    global_predictions = []\n",
    "    for learner in learners:\n",
    "        global_predictions.append([])\n",
    "        for inp,lab in global_loader:\n",
    "            _, preds = learner(inp.to(device)).max(1)\n",
    "            global_predictions[-1] += preds.data.cpu().numpy().tolist()\n",
    "    global_predictions = np.array(global_predictions)\n",
    "\n",
    "    certain_global = []\n",
    "    correct_count = 0\n",
    "    for i in range(len(global_trainset)):\n",
    "        tmp = np.zeros(10) #10 classes\n",
    "        for pred in global_predictions[:, i]:\n",
    "            tmp[pred] += 1\n",
    "        if tmp.max() >= theta:\n",
    "            certain_global.append((global_trainset[i][0], np.argmax(tmp)))\n",
    "            if np.argmax(tmp) == global_trainset[i][1]:\n",
    "                correct_count += 1\n",
    "    print(\"Certain predictions amount\", len(certain_global), \"with correct in them\", correct_count)\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(n_learners):\n",
    "        print(\"learner\", i)\n",
    "        local_dataset = local_sets[i]\n",
    "        net = train_learner(local_dataset + certain_global, epochs=epochs, net = learners[i])\n",
    "        acc += test(net)\n",
    "        learners[i] = net\n",
    "        \n",
    "    return learners, acc/n_learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "086a18ec-09d6-4ba9-a14d-3f97a7872a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local data 10000\n",
      "global data 40000\n"
     ]
    }
   ],
   "source": [
    "local_trainset = torch.utils.data.Subset(trainset, list(range(0, 10000)))\n",
    "print(\"local data\", len(local_trainset))\n",
    "global_trainset = torch.utils.data.Subset(trainset, list(range(10000, 50000)))\n",
    "print(\"global data\", len(global_trainset))\n",
    "global_loader = torch.utils.data.DataLoader(global_trainset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25d75d36-dc2a-4278-ab9e-d4e831500771",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.25\n",
    "unsorted_local_trainset = torch.utils.data.Subset(local_trainset, list(range(math.floor(p*len(local_trainset)))))\n",
    "sorted_local_trainset = {}\n",
    "for e in torch.utils.data.Subset(local_trainset, list(range(math.floor(p*len(local_trainset)), len(local_trainset)))):\n",
    "    if sorted_local_trainset.get(e[1]) is None:\n",
    "        sorted_local_trainset[e[1]] = []\n",
    "    sorted_local_trainset[e[1]].append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d91d559-542c-4302-8b5f-d0100b72c3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 5 size 701\n",
      "class 3 size 772\n",
      "class 7 size 748\n",
      "class 6 size 780\n",
      "class 0 size 752\n",
      "class 9 size 731\n",
      "class 2 size 777\n",
      "class 1 size 731\n",
      "class 4 size 737\n",
      "class 8 size 771\n"
     ]
    }
   ],
   "source": [
    "for k in sorted_local_trainset:\n",
    "    print(\"class\", k, \"size\", len(sorted_local_trainset[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "878eaf96-0834-46c9-9ec3-3c045d418dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_learners = 5\n",
    "uns_local_ds = len(unsorted_local_trainset)//n_learners\n",
    "theta = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0b6e51f-4925-4be7-b45a-e234e727ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_sets = []\n",
    "for i in range(n_learners):\n",
    "    local_sets.append([])\n",
    "    local_sets[i] += sorted_local_trainset[i]\n",
    "    local_sets[i] += sorted_local_trainset[i+5]\n",
    "    local_sets[i] += torch.utils.data.Subset(unsorted_local_trainset, list(range(uns_local_ds*i, uns_local_ds*(i+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f4203cd-8ac7-4d62-99bf-ecf8b49ed2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(local_sets, open(os.path.join(savedir, \"local_sets\"), \"wb\"))\n",
    "pickle.dump(global_trainset, open(os.path.join(savedir, \"global_trainset\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18d5efca-bbfd-4bd0-a2e9-336ad8d3a4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953\n",
      "2011\n",
      "2025\n",
      "2043\n",
      "1968\n"
     ]
    }
   ],
   "source": [
    "for l in local_sets:\n",
    "    print(len(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6f05057-95ed-4bfc-98b5-2702fd6f113d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner 0\n",
      "Epoch0, Loss: 1.468\n",
      "Epoch10, Loss: 0.026\n",
      "Epoch20, Loss: 0.001\n",
      "Epoch30, Loss: 0.000\n",
      "Epoch40, Loss: 0.000\n",
      "Epoch50, Loss: 0.000\n",
      "Epoch60, Loss: 0.000\n",
      "Epoch70, Loss: 0.000\n",
      "Epoch80, Loss: 0.000\n",
      "Epoch90, Loss: 0.000\n",
      "Loss: 5.318 | Acc: 26.950% (2695/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 1.337\n",
      "Epoch10, Loss: 0.034\n",
      "Epoch20, Loss: 0.001\n",
      "Epoch30, Loss: 0.019\n",
      "Epoch40, Loss: 0.004\n",
      "Epoch50, Loss: 0.001\n",
      "Epoch60, Loss: 0.000\n",
      "Epoch70, Loss: 0.000\n",
      "Epoch80, Loss: 0.000\n",
      "Epoch90, Loss: 0.000\n",
      "Loss: 4.656 | Acc: 30.330% (3033/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 1.522\n",
      "Epoch10, Loss: 0.080\n",
      "Epoch20, Loss: 0.001\n",
      "Epoch30, Loss: 0.000\n",
      "Epoch40, Loss: 0.000\n",
      "Epoch50, Loss: 0.000\n",
      "Epoch60, Loss: 0.000\n",
      "Epoch70, Loss: 0.000\n",
      "Epoch80, Loss: 0.000\n",
      "Epoch90, Loss: 0.000\n",
      "Loss: 5.042 | Acc: 26.710% (2671/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 1.459\n",
      "Epoch10, Loss: 0.015\n",
      "Epoch20, Loss: 0.001\n",
      "Epoch30, Loss: 0.000\n",
      "Epoch40, Loss: 0.000\n",
      "Epoch50, Loss: 0.000\n",
      "Epoch60, Loss: 0.000\n",
      "Epoch70, Loss: 0.000\n",
      "Epoch80, Loss: 0.000\n",
      "Epoch90, Loss: 0.000\n",
      "Loss: 5.511 | Acc: 24.820% (2482/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 1.494\n",
      "Epoch10, Loss: 0.027\n",
      "Epoch20, Loss: 0.001\n",
      "Epoch30, Loss: 0.000\n",
      "Epoch40, Loss: 0.000\n",
      "Epoch50, Loss: 0.000\n",
      "Epoch60, Loss: 0.000\n",
      "Epoch70, Loss: 0.000\n",
      "Epoch80, Loss: 0.000\n",
      "Epoch90, Loss: 0.000\n",
      "Loss: 5.328 | Acc: 25.880% (2588/10000)\n",
      "Average accuracy of local workers 0.26938\n"
     ]
    }
   ],
   "source": [
    "learners = []\n",
    "acc = 0\n",
    "for i in range(n_learners):\n",
    "    print(\"learner\", i)\n",
    "    local_dataset = local_sets[i]\n",
    "    net = train_learner(local_dataset, epochs=100)\n",
    "    acc += test(net)\n",
    "    learners.append(net)\n",
    "    torch.save(net, os.path.join(savedir, \"learner\"+str(i)))\n",
    "print(\"Average accuracy of local workers\", acc/n_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b23f99b9-961f-4821-925c-e50b03e3c1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certain predictions amount 662 with correct in them 538\n",
      "learner 0\n",
      "Epoch0, Loss: 0.605\n",
      "Epoch10, Loss: 0.001\n",
      "Loss: 4.309 | Acc: 35.480% (3548/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.458\n",
      "Epoch10, Loss: 0.001\n",
      "Loss: 4.018 | Acc: 36.570% (3657/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.483\n",
      "Epoch10, Loss: 0.001\n",
      "Loss: 4.311 | Acc: 33.920% (3392/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.486\n",
      "Epoch10, Loss: 0.002\n",
      "Loss: 4.874 | Acc: 32.960% (3296/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.693\n",
      "Epoch10, Loss: 0.131\n",
      "Loss: 4.398 | Acc: 33.540% (3354/10000)\n",
      "Average accuracy of local workers 0.34493999999999997\n",
      "Certain predictions amount 6234 with correct in them 4587\n",
      "learner 0\n",
      "Epoch0, Loss: 0.458\n",
      "Epoch10, Loss: 0.005\n",
      "Loss: 4.482 | Acc: 44.590% (4459/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.350\n",
      "Epoch10, Loss: 0.004\n",
      "Loss: 4.769 | Acc: 41.380% (4138/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.414\n",
      "Epoch10, Loss: 0.086\n",
      "Loss: 4.157 | Acc: 41.480% (4148/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.373\n",
      "Epoch10, Loss: 0.014\n",
      "Loss: 5.171 | Acc: 40.470% (4047/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.345\n",
      "Epoch10, Loss: 0.003\n",
      "Loss: 4.621 | Acc: 42.350% (4235/10000)\n",
      "Average accuracy of local workers 0.42054\n",
      "Certain predictions amount 17922 with correct in them 11083\n",
      "learner 0\n",
      "Epoch0, Loss: 0.366\n",
      "Epoch10, Loss: 0.013\n",
      "Loss: 5.831 | Acc: 46.020% (4602/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.310\n",
      "Epoch10, Loss: 0.008\n",
      "Loss: 6.314 | Acc: 43.600% (4360/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.306\n",
      "Epoch10, Loss: 0.007\n",
      "Loss: 6.199 | Acc: 44.590% (4459/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.366\n",
      "Epoch10, Loss: 0.015\n",
      "Loss: 6.010 | Acc: 44.740% (4474/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.331\n",
      "Epoch10, Loss: 0.013\n",
      "Loss: 6.527 | Acc: 43.420% (4342/10000)\n",
      "Average accuracy of local workers 0.44474\n",
      "Certain predictions amount 27908 with correct in them 14789\n",
      "learner 0\n",
      "Epoch0, Loss: 0.351\n",
      "Epoch10, Loss: 0.012\n",
      "Loss: 7.550 | Acc: 45.430% (4543/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.310\n",
      "Epoch10, Loss: 0.019\n",
      "Loss: 7.862 | Acc: 44.020% (4402/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.355\n",
      "Epoch10, Loss: 0.012\n",
      "Loss: 8.042 | Acc: 43.970% (4397/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.362\n",
      "Epoch10, Loss: 0.018\n",
      "Loss: 7.702 | Acc: 44.300% (4430/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.351\n",
      "Epoch10, Loss: 0.012\n",
      "Loss: 8.164 | Acc: 43.990% (4399/10000)\n",
      "Average accuracy of local workers 0.44342000000000004\n",
      "Certain predictions amount 31957 with correct in them 15828\n",
      "learner 0\n",
      "Epoch0, Loss: 0.331\n",
      "Epoch10, Loss: 0.020\n",
      "Loss: 8.818 | Acc: 45.450% (4545/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.301\n",
      "Epoch10, Loss: 0.008\n",
      "Loss: 9.028 | Acc: 44.450% (4445/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.331\n",
      "Epoch10, Loss: 0.008\n",
      "Loss: 9.203 | Acc: 44.120% (4412/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.318\n",
      "Epoch10, Loss: 0.011\n",
      "Loss: 8.870 | Acc: 44.640% (4464/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.335\n",
      "Epoch10, Loss: 0.004\n",
      "Loss: 8.230 | Acc: 44.620% (4462/10000)\n",
      "Average accuracy of local workers 0.44656\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    learners, acc = tuning(learners, local_sets, theta, epochs=20)\n",
    "    print(\"Average accuracy of local workers\", acc)\n",
    "    for ind, l in enumerate(learners):\n",
    "        torch.save(l, os.path.join(savedir, \"learner\"+str(ind)+\"_tune\"+str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a77e5d-f528-4788-a110-cebffef1259e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
