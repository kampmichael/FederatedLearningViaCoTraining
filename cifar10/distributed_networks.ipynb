{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e063929a-18b2-4d3a-a590-e54c6fc5cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet18\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51696347-3713-461c-8cbf-9eccc66e788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = \"./saved_models/run7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf20e84-b0ad-447b-9a10-35560b2ae8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1e77300-7ca3-4e3c-8a04-108ccc8df33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "238304cb-83c8-48f5-a43d-ea33d140b13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e667ecf-c348-449f-b9f3-8b9379030259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, optimizer, epoch):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    if epoch%10==0:\n",
    "        print('Epoch%d, Loss: %.3f' % (epoch, train_loss/(batch_idx+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8432c55a-0531-49ae-a2be-2e96706f3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        print('Loss: %.3f | Acc: %.3f%% (%d/%d)' % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    return 1.0*correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10235ff8-69b4-4393-8951-4a51a0a6c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_learner(dataset, epochs, net=None):\n",
    "    if net is None:\n",
    "        net = ResNet18()\n",
    "        net = net.to(device)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.005, momentum=0.9)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "    for epoch in range(epochs):\n",
    "        train(net, trainloader, optimizer, epoch)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4afd064e-a702-49ac-a884-c1182a2facaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(learners, local_ds, theta, epochs):\n",
    "    global_predictions = []\n",
    "    for learner in learners:\n",
    "        global_predictions.append([])\n",
    "        for inp,lab in global_loader:\n",
    "            _, preds = learner(inp.to(device)).max(1)\n",
    "            global_predictions[-1] += preds.data.cpu().numpy().tolist()\n",
    "    global_predictions = np.array(global_predictions)\n",
    "\n",
    "    certain_global = []\n",
    "    correct_count = 0\n",
    "    for i in range(len(global_trainset)):\n",
    "        tmp = np.zeros(10) #10 classes\n",
    "        for pred in global_predictions[:, i]:\n",
    "            tmp[pred] += 1\n",
    "        if tmp.max() >= theta:\n",
    "            certain_global.append((global_trainset[i][0], np.argmax(tmp)))\n",
    "            if np.argmax(tmp) == global_trainset[i][1]:\n",
    "                correct_count += 1\n",
    "    print(\"Certain predictions amount\", len(certain_global), \"with correct in them\", correct_count)\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(n_learners):\n",
    "        print(\"learner\", i)\n",
    "        local_dataset = torch.utils.data.Subset(local_trainset, list(range(i*local_ds, (i+1)*local_ds)))\n",
    "        net = train_learner(local_dataset + certain_global, epochs=epochs, net = learners[i])\n",
    "        acc += test(net)\n",
    "        learners[i] = net\n",
    "        \n",
    "    return learners, acc/n_learners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d79a9a-f6cd-49b7-9f41-c0a9149010c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "local data 5000\n",
      "global data 45000\n"
     ]
    }
   ],
   "source": [
    "local_trainset = torch.utils.data.Subset(trainset, list(range(0, 5000)))\n",
    "print(\"local data\", len(local_trainset))\n",
    "global_trainset = torch.utils.data.Subset(trainset, list(range(5000, 50000)))\n",
    "print(\"global data\", len(global_trainset))\n",
    "global_loader = torch.utils.data.DataLoader(global_trainset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7141218-2c58-4510-a665-6f8cf115acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(local_trainset, open(os.path.join(savedir, \"local_trainset\"), \"wb\"))\n",
    "pickle.dump(global_trainset, open(os.path.join(savedir, \"global_trainset\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a1cc505-67d3-45ff-b4d7-4b0aa09218d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the local dataset 1000\n"
     ]
    }
   ],
   "source": [
    "n_learners = 5\n",
    "theta = 4\n",
    "local_ds = len(local_trainset)//n_learners\n",
    "print(\"Length of the local dataset\", local_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20745b45-24e4-4e10-bf82-888d27ee6e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learner 0\n",
      "Epoch0, Loss: 2.227\n",
      "Epoch10, Loss: 1.305\n",
      "Epoch20, Loss: 0.757\n",
      "Epoch30, Loss: 0.420\n",
      "Epoch40, Loss: 0.289\n",
      "Epoch50, Loss: 0.114\n",
      "Epoch60, Loss: 0.075\n",
      "Epoch70, Loss: 0.025\n",
      "Epoch80, Loss: 0.106\n",
      "Epoch90, Loss: 0.052\n",
      "Loss: 3.126 | Acc: 50.500% (5050/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 2.159\n",
      "Epoch10, Loss: 1.197\n",
      "Epoch20, Loss: 0.797\n",
      "Epoch30, Loss: 0.467\n",
      "Epoch40, Loss: 0.304\n",
      "Epoch50, Loss: 0.110\n",
      "Epoch60, Loss: 0.075\n",
      "Epoch70, Loss: 0.129\n",
      "Epoch80, Loss: 0.035\n",
      "Epoch90, Loss: 0.037\n",
      "Loss: 3.325 | Acc: 48.140% (4814/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 2.227\n",
      "Epoch10, Loss: 1.253\n",
      "Epoch20, Loss: 0.754\n",
      "Epoch30, Loss: 0.331\n",
      "Epoch40, Loss: 0.237\n",
      "Epoch50, Loss: 0.132\n",
      "Epoch60, Loss: 0.121\n",
      "Epoch70, Loss: 0.052\n",
      "Epoch80, Loss: 0.007\n",
      "Epoch90, Loss: 0.006\n",
      "Loss: 2.945 | Acc: 53.190% (5319/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 2.219\n",
      "Epoch10, Loss: 1.382\n",
      "Epoch20, Loss: 0.860\n",
      "Epoch30, Loss: 0.441\n",
      "Epoch40, Loss: 0.285\n",
      "Epoch50, Loss: 0.162\n",
      "Epoch60, Loss: 0.127\n",
      "Epoch70, Loss: 0.046\n",
      "Epoch80, Loss: 0.025\n",
      "Epoch90, Loss: 0.021\n",
      "Loss: 2.810 | Acc: 54.550% (5455/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 2.199\n",
      "Epoch10, Loss: 1.316\n",
      "Epoch20, Loss: 0.860\n",
      "Epoch30, Loss: 0.521\n",
      "Epoch40, Loss: 0.193\n",
      "Epoch50, Loss: 0.201\n",
      "Epoch60, Loss: 0.164\n",
      "Epoch70, Loss: 0.064\n",
      "Epoch80, Loss: 0.008\n",
      "Epoch90, Loss: 0.004\n",
      "Loss: 2.885 | Acc: 51.850% (5185/10000)\n",
      "Average accuracy of local workers 0.51646\n"
     ]
    }
   ],
   "source": [
    "learners = []\n",
    "acc = 0\n",
    "for i in range(n_learners):\n",
    "    print(\"learner\", i)\n",
    "    local_dataset = torch.utils.data.Subset(local_trainset, list(range(i*local_ds, (i+1)*local_ds)))\n",
    "    net = train_learner(local_dataset, epochs=100)\n",
    "    acc += test(net)\n",
    "    learners.append(net)\n",
    "    torch.save(net, os.path.join(savedir, \"learner\"+str(i)))\n",
    "print(\"Average accuracy of local workers\", acc/n_learners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "283d375b-5507-4bda-846f-3c45bb13dbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certain predictions amount 18704 with correct in them 15496\n",
      "learner 0\n",
      "Epoch0, Loss: 0.414\n",
      "Epoch10, Loss: 0.040\n",
      "Loss: 2.881 | Acc: 61.680% (6168/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.425\n",
      "Epoch10, Loss: 0.033\n",
      "Loss: 2.669 | Acc: 62.790% (6279/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.416\n",
      "Epoch10, Loss: 0.035\n",
      "Loss: 2.938 | Acc: 61.750% (6175/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.404\n",
      "Epoch10, Loss: 0.045\n",
      "Loss: 2.683 | Acc: 62.780% (6278/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.404\n",
      "Epoch10, Loss: 0.046\n",
      "Loss: 2.742 | Acc: 62.840% (6284/10000)\n",
      "Average accuracy of local workers 0.62368\n",
      "Certain predictions amount 31870 with correct in them 24163\n",
      "learner 0\n",
      "Epoch0, Loss: 0.330\n",
      "Epoch10, Loss: 0.031\n",
      "Loss: 3.295 | Acc: 65.030% (6503/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.333\n",
      "Epoch10, Loss: 0.034\n",
      "Loss: 3.071 | Acc: 65.110% (6511/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.330\n",
      "Epoch10, Loss: 0.035\n",
      "Loss: 3.218 | Acc: 64.810% (6481/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.342\n",
      "Epoch10, Loss: 0.035\n",
      "Loss: 3.158 | Acc: 65.090% (6509/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.334\n",
      "Epoch10, Loss: 0.033\n",
      "Loss: 3.161 | Acc: 64.720% (6472/10000)\n",
      "Average accuracy of local workers 0.6495200000000001\n",
      "Certain predictions amount 36226 with correct in them 26656\n",
      "learner 0\n",
      "Epoch0, Loss: 0.308\n",
      "Epoch10, Loss: 0.026\n",
      "Loss: 3.434 | Acc: 66.800% (6680/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.295\n",
      "Epoch10, Loss: 0.026\n",
      "Loss: 3.461 | Acc: 66.430% (6643/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.298\n",
      "Epoch10, Loss: 0.024\n",
      "Loss: 3.465 | Acc: 66.970% (6697/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.301\n",
      "Epoch10, Loss: 0.023\n",
      "Loss: 3.437 | Acc: 67.240% (6724/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.305\n",
      "Epoch10, Loss: 0.021\n",
      "Loss: 3.400 | Acc: 67.030% (6703/10000)\n",
      "Average accuracy of local workers 0.66894\n",
      "Certain predictions amount 38542 with correct in them 27898\n",
      "learner 0\n",
      "Epoch0, Loss: 0.284\n",
      "Epoch10, Loss: 0.021\n",
      "Loss: 3.678 | Acc: 67.810% (6781/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.282\n",
      "Epoch10, Loss: 0.014\n",
      "Loss: 3.584 | Acc: 67.470% (6747/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.284\n",
      "Epoch10, Loss: 0.017\n",
      "Loss: 3.664 | Acc: 67.690% (6769/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.289\n",
      "Epoch10, Loss: 0.019\n",
      "Loss: 3.694 | Acc: 68.040% (6804/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.281\n",
      "Epoch10, Loss: 0.019\n",
      "Loss: 3.655 | Acc: 67.480% (6748/10000)\n",
      "Average accuracy of local workers 0.67698\n",
      "Certain predictions amount 39865 with correct in them 28663\n",
      "learner 0\n",
      "Epoch0, Loss: 0.263\n",
      "Epoch10, Loss: 0.015\n",
      "Loss: 3.901 | Acc: 67.930% (6793/10000)\n",
      "learner 1\n",
      "Epoch0, Loss: 0.273\n",
      "Epoch10, Loss: 0.010\n",
      "Loss: 3.730 | Acc: 68.000% (6800/10000)\n",
      "learner 2\n",
      "Epoch0, Loss: 0.266\n",
      "Epoch10, Loss: 0.014\n",
      "Loss: 3.730 | Acc: 68.580% (6858/10000)\n",
      "learner 3\n",
      "Epoch0, Loss: 0.269\n",
      "Epoch10, Loss: 0.013\n",
      "Loss: 3.717 | Acc: 68.060% (6806/10000)\n",
      "learner 4\n",
      "Epoch0, Loss: 0.266\n",
      "Epoch10, Loss: 0.013\n",
      "Loss: 3.818 | Acc: 67.830% (6783/10000)\n",
      "Average accuracy of local workers 0.6808000000000001\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    learners, acc = tuning(learners, local_ds, theta, epochs=20)\n",
    "    print(\"Average accuracy of local workers\", acc)\n",
    "    for ind, l in enumerate(learners):\n",
    "        torch.save(l, os.path.join(savedir, \"learner\"+str(ind)+\"_tune\"+str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684e2f4f-ea2a-4894-a256-ae4cad08d35a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
