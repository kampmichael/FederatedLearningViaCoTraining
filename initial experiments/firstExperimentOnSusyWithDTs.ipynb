{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.971370</td>\n",
       "      <td>0.063970</td>\n",
       "      <td>-1.223079</td>\n",
       "      <td>-0.754071</td>\n",
       "      <td>-0.337943</td>\n",
       "      <td>1.669839</td>\n",
       "      <td>2.835978</td>\n",
       "      <td>-1.217158</td>\n",
       "      <td>-1.110447</td>\n",
       "      <td>3.769216</td>\n",
       "      <td>0.072541</td>\n",
       "      <td>-0.739418</td>\n",
       "      <td>-1.100135</td>\n",
       "      <td>-1.164297</td>\n",
       "      <td>-0.888814</td>\n",
       "      <td>-1.274252</td>\n",
       "      <td>0.739308</td>\n",
       "      <td>0.775052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.808163</td>\n",
       "      <td>-0.133904</td>\n",
       "      <td>-0.708738</td>\n",
       "      <td>-0.837198</td>\n",
       "      <td>-1.609266</td>\n",
       "      <td>-0.767390</td>\n",
       "      <td>0.251972</td>\n",
       "      <td>0.503158</td>\n",
       "      <td>0.932196</td>\n",
       "      <td>-0.430650</td>\n",
       "      <td>-0.753885</td>\n",
       "      <td>-0.100052</td>\n",
       "      <td>1.248020</td>\n",
       "      <td>1.191606</td>\n",
       "      <td>-0.638962</td>\n",
       "      <td>0.901269</td>\n",
       "      <td>0.311788</td>\n",
       "      <td>-0.223392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.900671</td>\n",
       "      <td>-0.973143</td>\n",
       "      <td>0.692047</td>\n",
       "      <td>-0.841417</td>\n",
       "      <td>0.889265</td>\n",
       "      <td>-0.676206</td>\n",
       "      <td>1.183526</td>\n",
       "      <td>1.530473</td>\n",
       "      <td>2.297123</td>\n",
       "      <td>-1.003637</td>\n",
       "      <td>-0.685342</td>\n",
       "      <td>0.026117</td>\n",
       "      <td>1.236725</td>\n",
       "      <td>0.641831</td>\n",
       "      <td>-0.384872</td>\n",
       "      <td>1.146696</td>\n",
       "      <td>1.129964</td>\n",
       "      <td>-0.681261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.450551</td>\n",
       "      <td>-0.687974</td>\n",
       "      <td>-0.675082</td>\n",
       "      <td>0.901611</td>\n",
       "      <td>-0.691327</td>\n",
       "      <td>0.621912</td>\n",
       "      <td>0.100342</td>\n",
       "      <td>-0.381147</td>\n",
       "      <td>-0.463096</td>\n",
       "      <td>1.363355</td>\n",
       "      <td>0.284546</td>\n",
       "      <td>-0.054335</td>\n",
       "      <td>-0.576317</td>\n",
       "      <td>-1.164297</td>\n",
       "      <td>0.133791</td>\n",
       "      <td>-1.533846</td>\n",
       "      <td>0.356272</td>\n",
       "      <td>-0.660245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.791347</td>\n",
       "      <td>1.095944</td>\n",
       "      <td>1.509983</td>\n",
       "      <td>-0.378555</td>\n",
       "      <td>0.637195</td>\n",
       "      <td>-0.740988</td>\n",
       "      <td>-0.776014</td>\n",
       "      <td>1.318837</td>\n",
       "      <td>-0.934584</td>\n",
       "      <td>0.359417</td>\n",
       "      <td>-0.812766</td>\n",
       "      <td>-0.999443</td>\n",
       "      <td>-0.520532</td>\n",
       "      <td>-0.810791</td>\n",
       "      <td>-0.868423</td>\n",
       "      <td>-1.049513</td>\n",
       "      <td>-0.610517</td>\n",
       "      <td>-0.197329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2         3         4         5         6         7   \\\n",
       "0  1.0  0.971370  0.063970 -1.223079 -0.754071 -0.337943  1.669839  2.835978   \n",
       "1  1.0 -0.808163 -0.133904 -0.708738 -0.837198 -1.609266 -0.767390  0.251972   \n",
       "2  1.0 -0.900671 -0.973143  0.692047 -0.841417  0.889265 -0.676206  1.183526   \n",
       "3  1.0  0.450551 -0.687974 -0.675082  0.901611 -0.691327  0.621912  0.100342   \n",
       "4 -1.0 -0.791347  1.095944  1.509983 -0.378555  0.637195 -0.740988 -0.776014   \n",
       "\n",
       "         8         9         10        11        12        13        14  \\\n",
       "0 -1.217158 -1.110447  3.769216  0.072541 -0.739418 -1.100135 -1.164297   \n",
       "1  0.503158  0.932196 -0.430650 -0.753885 -0.100052  1.248020  1.191606   \n",
       "2  1.530473  2.297123 -1.003637 -0.685342  0.026117  1.236725  0.641831   \n",
       "3 -0.381147 -0.463096  1.363355  0.284546 -0.054335 -0.576317 -1.164297   \n",
       "4  1.318837 -0.934584  0.359417 -0.812766 -0.999443 -0.520532 -0.810791   \n",
       "\n",
       "         15        16        17        18  \n",
       "0 -0.888814 -1.274252  0.739308  0.775052  \n",
       "1 -0.638962  0.901269  0.311788 -0.223392  \n",
       "2 -0.384872  1.146696  1.129964 -0.681261  \n",
       "3  0.133791 -1.533846  0.356272 -0.660245  \n",
       "4 -0.868423 -1.049513 -0.610517 -0.197329  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "susyDataset = \"path/to/SUSYnormalized.csv\"\n",
    "df=pd.read_csv(susyDataset, sep=',',header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3698112, 18) (3698112,)\n",
      "(500, 18) (500,) (10000, 18) (10000,) (10000, 18) (10000,) (1000, 18) (1000,)\n"
     ]
    }
   ],
   "source": [
    "Y = df.iloc[:,0].to_numpy()\n",
    "X = df.iloc[:,1:].to_numpy()\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "paramFrac = 0.2\n",
    "trainFrac = 0.4\n",
    "testfrac = 0.2\n",
    "globalfrac = 0.4\n",
    "\n",
    "n = 5000\n",
    "nTrain = 500#int(n*trainFrac)\n",
    "nTest = 10000#int(n*testfrac)\n",
    "nGlobal = 10000#int(n*globalfrac)\n",
    "nParam = 1000#int(n*paramFrac)\n",
    "\n",
    "Xglobal = X[nTrain + nTest:nTrain + nTest + nGlobal]\n",
    "Yglobal = Y[nTrain + nTest:nTrain + nTest + nGlobal]\n",
    "Xtest = X[nTrain:nTrain + nTest]\n",
    "Ytest = Y[nTrain:nTrain + nTest]\n",
    "Xparam = X[nTrain + nTest + nGlobal:nTrain + nTest + nGlobal + nParam]\n",
    "Yparam = Y[nTrain + nTest + nGlobal:nTrain + nTest + nGlobal + nParam]\n",
    "X = X[:nTrain]\n",
    "Y = Y[:nTrain]\n",
    "\n",
    "print(X.shape, Y.shape, Xglobal.shape, Yglobal.shape, Xtest.shape, Ytest.shape, Xparam.shape, Yparam.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into local datasets\n",
    "\n",
    "Training data is separated by drawing half of each local dataset uniform at random and half of the dataset based on the value of one selected feature.\n",
    "\n",
    "For the selected feature col (I have chosen feature 0 rather randomly, here), its values are binned by frequency (each bin contains an equal amount of data points) and each bin is appended to one local dataset. Thus, half of each local dataset is uniform, the other half has one particular feature value in a fixed range that is different from all other local datasets. Thus, there is some mild form on non-iid-ness in the distribution of X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalFrequencyIntervals(vals, bins):\n",
    "    n = len(vals)\n",
    "    intervals = np.interp(np.linspace(0, n, bins + 1), np.arange(n), np.sort(vals))\n",
    "    intervals[-1] += 0.00001 #this should solve rounding errors\n",
    "    return intervals\n",
    "\n",
    "def getLearner(i, intervals, X, col):\n",
    "    for j in range(len(intervals)):\n",
    "        if X[i,col] < intervals[j]:\n",
    "            return j - 1\n",
    "    print(X[i,col], intervals)\n",
    "\n",
    "def distributeDataset(X, Y, col, num_learners, frac_colBin = 0.5):\n",
    "    n = Y.shape[0]\n",
    "    n_colBin = int(n*frac_colBin)\n",
    "    \n",
    "    \n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    indColBin    = indices[:n_colBin]\n",
    "    indNonColBin = indices[n_colBin:]\n",
    "    \n",
    "    Xs = np.array_split(X[indNonColBin,:], num_learners)    \n",
    "    Ys = np.array_split(Y[indNonColBin], num_learners)    \n",
    "    \n",
    "    \n",
    "    vals = X[indColBin,col]\n",
    "    intervals = equalFrequencyIntervals(vals, num_learners)\n",
    "    \n",
    "    Idxs = [[] for _ in range(num_learners)]\n",
    "    count = 0\n",
    "    for i in indColBin:\n",
    "        l = getLearner(i, intervals, X, col)\n",
    "        Idxs[l].append(i)\n",
    "        count += 1\n",
    "        \n",
    "        \n",
    "    for l in range(num_learners):\n",
    "        Xcolbin = X[Idxs[l],:]\n",
    "        Ycolbin = Y[Idxs[l]]\n",
    "        Xs[l] = np.vstack([Xs[l],Xcolbin])\n",
    "        Ys[l] = np.hstack([Ys[l],Ycolbin])\n",
    "    return Xs, Ys \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 18) (100,)\n",
      "(100, 18) (100,)\n",
      "(100, 18) (100,)\n",
      "(100, 18) (100,)\n",
      "(100, 18) (100,)\n"
     ]
    }
   ],
   "source": [
    "num_learners = 5\n",
    "col          = 0\n",
    "\n",
    "Xs, Ys = distributeDataset(X,Y, col, num_learners)\n",
    "for l in range(num_learners):\n",
    "    print(Xs[l].shape, Ys[l].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train some local models on parts of the local data\n",
    "\n",
    "And let's use only decision trees for now...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, a parameter evaluation for the decision trees\n",
    "\n",
    "That's a standard parameter evaluation on a small, independent dataset with a reasonable range of parameters for decision trees.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 4, 'min_samples_leaf': 31, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'max_depth':list(range(1,10)), 'min_samples_split':list(range(2,50, 4)), 'min_samples_leaf' : list(range(1,50, 5)), 'criterion' : ['gini', 'entropy']}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "clf = GridSearchCV(dt, parameters)\n",
    "clf.fit(Xparam, Yparam)\n",
    "\n",
    "optParams = clf.best_params_\n",
    "print(optParams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the \"distributed\" training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "examplesPerLearner = 599999\n",
    "max_depth = 5\n",
    "results = {}\n",
    "\n",
    "learners = []\n",
    "for l in range(num_learners):\n",
    "    Xl = Xs[l][:examplesPerLearner]\n",
    "    Yl = Ys[l][:examplesPerLearner]\n",
    "    clf = DecisionTreeClassifier(**optParams)\n",
    "    clf.fit(Xl, Yl)\n",
    "    learners.append(clf)\n",
    "    \n",
    "    ytrainpred = clf.predict(Xl)\n",
    "    ypred = clf.predict(Xtest)\n",
    "    \n",
    "    trainACC = accuracy_score(Yl, ytrainpred)\n",
    "    testACC = accuracy_score(Ytest, ypred)\n",
    "    \n",
    "    results[l] = {'train' : trainACC, 'test' : testACC}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'train': 0.79, 'test': 0.6949}, 1: {'train': 0.83, 'test': 0.7114}, 2: {'train': 0.72, 'test': 0.7266}, 3: {'train': 0.73, 'test': 0.6325}, 4: {'train': 0.72, 'test': 0.7241}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will have them make predictions on the global data\n",
    "\n",
    "The global dataset is assumed to be unlabelled and the predictions of the local models are used to generate labels.\n",
    "\n",
    "The labels are generated by taking the majority vote of local models as the actual label. To make those more certain, only those data points are added to the \"confident global dataset\", for which 4 of 5 local models agree (This is controlled by the parameter theta below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2662,) (2662, 18) (2662,) (10000, 18)\n"
     ]
    }
   ],
   "source": [
    "theta = 0.0\n",
    "thetaPos = num_learners * (1-theta) \n",
    "thetaNeg = num_learners * theta\n",
    "\n",
    "globalPreds = []\n",
    "for l in range(num_learners):\n",
    "    Ypred_global = learners[l].predict(Xglobal)\n",
    "    globalPreds.append(Ypred_global)\n",
    "globalPreds = np.sum(np.array(globalPreds), axis=0) #take the sum to get an estimate of the consensus (if sum = 5, all learners say it's 1, if sum = 0 all say it's 0)\n",
    "\n",
    "#we now want to remove those data points from the global set for which the local models are not agreeing very much\n",
    "confidentGlobalPreds = []\n",
    "confidentIdxs = []\n",
    "for i in range(globalPreds.shape[0]):\n",
    "    pred = globalPreds[i]\n",
    "    if pred >= thetaPos:\n",
    "        confidentGlobalPreds.append(1.0)\n",
    "        confidentIdxs.append(i)\n",
    "    elif pred >= thetaPos:\n",
    "        confidentGlobalPreds.append(0.0)\n",
    "        confidentIdxs.append(i)\n",
    "confidentGlobalPreds = np.array(confidentGlobalPreds)\n",
    "        \n",
    "Xconfglobal = Xglobal[confidentIdxs,:]\n",
    "Yconfglobal = Yglobal[confidentIdxs]\n",
    "print(confidentGlobalPreds.shape, Xconfglobal.shape, Yconfglobal.shape, Xglobal.shape )        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain local models by adding the confident global predictions (not the original labels, though)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "learnersGlobal = []\n",
    "for l in range(num_learners):\n",
    "    Xl = np.vstack([Xs[l][:examplesPerLearner], Xconfglobal])\n",
    "    Yl = np.hstack([Ys[l][:examplesPerLearner], confidentGlobalPreds])\n",
    "    clf = DecisionTreeClassifier(**optParams)\n",
    "    clf.fit(Xl, Yl)\n",
    "    learnersGlobal.append(clf)\n",
    "    \n",
    "    ytrainpred = clf.predict(Xl)\n",
    "    ypred = clf.predict(Xtest)\n",
    "    \n",
    "    trainACC = accuracy_score(Yl, ytrainpred)\n",
    "    testACC = accuracy_score(Ytest, ypred)\n",
    "    \n",
    "    results[l].update({'train_wGlobal' : trainACC, 'test_wGlobal' : testACC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {'train': 0.79, 'test': 0.6949, 'train_wGlobal': 0.9920347574221579, 'test_wGlobal': 0.7241}, 1: {'train': 0.83, 'test': 0.7114, 'train_wGlobal': 0.9913106444605359, 'test_wGlobal': 0.7244}, 2: {'train': 0.72, 'test': 0.7266, 'train_wGlobal': 0.9887762490948588, 'test_wGlobal': 0.7244}, 3: {'train': 0.73, 'test': 0.6325, 'train_wGlobal': 0.9902244750181028, 'test_wGlobal': 0.6325}, 4: {'train': 0.72, 'test': 0.7241, 'train_wGlobal': 0.9898624185372918, 'test_wGlobal': 0.7245}}\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6979 0.70598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = [results[l]['test'] for l in results]\n",
    "testGlobal = [results[l]['test_wGlobal'] for l in results]\n",
    "\n",
    "testAvg = np.average(np.array(test))\n",
    "testGlobalAvg = np.average(np.array(testGlobal))\n",
    "\n",
    "print(testAvg, testGlobalAvg)\n",
    "\n",
    "x = np.arange(num_learners)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "width = 0.4\n",
    "\n",
    "rects1 = ax.bar(x - width/2, test, width, label='test ACC (avg = '+str(round(testAvg,2))+')')\n",
    "rects2 = ax.bar(x + width/2, testGlobal, width, label='test ACC trained with global data (avg = '+str(round(testGlobalAvg,2))+')')\n",
    "\n",
    "#ax.hlines(testAvg, 0  - width, num_learners - width, label = 'average test ACC', colors='b', zorder=10)\n",
    "#ax.hlines(testGlobalAvg, 0  - width, num_learners - width, label = 'average test ACC with global', colors='r', zorder=12)\n",
    "\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xlabel('learner/client')\n",
    "ax.set_title('Accuracy of Local Training with and without Global Data')\n",
    "ax.set_xticklabels(list(range(num_learners+1)))\n",
    "ax.set_ylim((0,1))\n",
    "ax.legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('testAcc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
